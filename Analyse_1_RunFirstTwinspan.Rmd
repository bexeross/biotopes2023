---
title: "Prepare input data with analysis specific modifications and fit first Twinspan model"
authors: Genoveva Gonzalez Mirelis and Rebecca Ross
date: "Last Rendered on `r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_notebook: 
    toc: yes
    toc_depth: 2
    toc_float: yes
    fig_width: 7
    fig_height: 7
always_allow_html: true 
---

## Libraries
Load necessary libraries
```{r}
# # NB if you need to install twinspan you need to RUN R/RSTUDIO AS ADMINSTRATOR
# library(devtools)
# devtools::install_github("jarioksa/twinspan")
# 
# #option 2 if that fails
# #install.packages("twinspan", repos="https://jarioksa.github.io/drat/")

###

library(twinspan)
library(tidyverse)
library(rgdal)
library(sf)
library(rgeos)
```

## Load input samples by species data (made in prep steps 1-3)
```{r}
trimmedwide <- read.csv(file.path(dataPath,"widedata_2022-12-07.csv"))
```

## Twinspan specific preparations

### Check species included
```{r}
colnames(trimmedwide)
```

### check number of species per sample
```{r}
sppPerSamp<-trimmedwide %>% mutate(noSpp=rowSums(.[3:251]!=0)) %>% select(c("SampID", "noSpp"))%>% arrange(desc(noSpp))
#MAX NO OF SPP PER SAMP
message("Maximum number of species per sample")
max(sppPerSamp$noSpp)
message("Minimum number of species per sample")
min(sppPerSamp$noSpp)
```

### check number of samples per species
```{r}
sampPerSp<-as.data.frame(colSums(trimmedwide[3:251]!=0)) %>% rename("noSamp"="colSums(trimmedwide[3:251] != 0)") %>% arrange(noSamp)
message("Maximum number of samples per species")
max(sampPerSp$noSamp)
message("Minimum number of samples per species")
min(sampPerSp$noSamp)
```
## Threshold the number of spp/samp samp/spp

```{r}
minNoSppPerSamp<-4
minNoSampPerSpp<-4


```




# Twinspan
Perform the twinspan analysis

### Fit the twinspan model
Turn on or off the filters as you wish
```{r, warning=FALSE}

samples <- trimmedwide 

coredata <- left_join(samples, trimmedwide)
coredata <- coredata %>% select(-SampID)
row.names(coredata) <- samples$SampID

#cutlevels = c(0,100,200,400,1000)
cutlevelsPaal = c(0,1,2,5,10,20)

tw_1 <- coredata %>%
  select(which(!is.na(colSums(.)))) %>%
  #mutate_all(sqrt)%>%
  twinspan(cutlevels = cutlevelsPaal, levmax = 15, groupmin = 3) #change groupmin to 4? (see minNoSampPerSpp)

#summary(tw_1)
eval <- misclassified(tw_1)
eval <- with(eval,  data.frame(SampID = samples$SampID[index], class = class, predicted = predicted))
eval
```
## check excluded samples/stations
outputting for more detailed explorations
```{r}
# # excluded<-refer %>% filter(sample_no%in%unique(sample_info$VL)) %>%
# #   filter(!(sample_no%in%good))
# # 
# # write.csv(excluded, file = file.path(outPath, ("excluded_megaAnalysis.csv")))
# #   
# 
# excl.samp<-sample_info %>%
#   anti_join(tw_1.df, by=c("SampID"="rowname"))%>%
#   left_join(refer, by=c("VL"="sample_no"))
# 
# write.csv(excl.samp, file = file.path(outPath, ("excluded_samples.csv")))

```

