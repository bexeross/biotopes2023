---
title: "Compile Filtered Dataset - R Notebook"
authors:  Rebecca Ross and Genoveva Gonzalez Mirelis
date: "Last Rendered on `r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_notebook: 
    toc: yes
    toc_depth: 2
    toc_float: yes
    fig_width: 7
    fig_height: 7
always_allow_html: true 
---

NB This script is copied from the Mareano/NiN v3.0 work "videoEnvDataPrep" project, and amended for biotope analysis settings.


#Assumptions
This script allows you to run species/ station filters/ any other filters in what ever order suits you, then compile the final objects here to ensure you are getting the up-to-date filters applied.

Assumes:
- pre run config
- pre run Filters scripts


#Libraries
```{r}
library(dplyr)
library(tidyr)
```
#inputs
Loaded from file to ensure stable random subsample - check dates are correct version

```{r}
# read needed shapefile
dsn <- "U:/Mareano/VIDEOLAB/VIDEO DATA/200m_scale_species_by_sample/GIS_Data"
gbk <- readOGR(dsn = dsn, layer = "MAREANO_GBK-sampled_areas_311221") 

# filters
activeSppFilter<-read.csv(file.path(dataPath,"biotopeSpeciesfilter_2022-12-07.csv"))

## SELECT CORRECT ONE
#activeStFilter<-read.csv(file.path(dataPath,"activeSubsampleOslo_2022-10-19.csv")) # wholeDataset "OSLO"
activeStFilter<-read.csv(file.path(dataPath,"biotopeInputSamples_2022-12-07.csv")) # subsampled 1perR

length(unique(activeSppFilter$SampID)) # number of samples in sp filtered dataset
length(unique(activeStFilter$SampID)) # number of samples in st filtered dataset
```
### check location of sample subset
```{r}
sfilt_fin_spat <- activeStFilter %>%
  select(x_coord,y_coord) %>%
  SpatialPoints

par(mar = c(0, 0, 0, 0) + 0.1)
plot(gbk, border="green")
plot(sfilt_fin_spat, axes = FALSE, cex = 0.6, add = TRUE) 
box() 
```


#Combine filters to form dataset

Use output of stationFilters to select from filtered species data 
```{r}
stFilt.sel.sppDens<-activeSppFilter%>% filter(SampID%in%activeStFilter$SampID) 

#check effect
length(unique(activeSppFilter$SampID)) # number of samples in sp filtered dataset
length(unique(stFilt.sel.sppDens$SampID)) # number of samples in station filtered sp filtered dataset 
```

### check location of species filter applied to sample filter subset
```{r}
spstfilt_fin<-sample_info %>%
  filter(SampID2%in%stFilt.sel.sppDens$SampID)


spstfilt_fin_spat <- spstfilt_fin %>%
  select(x_coord,y_coord) %>%
  SpatialPoints

par(mar = c(0, 0, 0, 0) + 0.1)
plot(gbk, border="green")
plot(spstfilt_fin_spat, axes = FALSE, cex = 0.6, add = TRUE) 
box() 
```



#Change to wide format for analyses

```{r}

wideData <- stFilt.sel.sppDens %>% select(-c(TotAbu_pseudocount, X)) %>%
  mutate(clean_taxonomy = gsub(" ","_",clean_taxonomy)) %>%
 # mutate(clean_taxonomy = gsub("\\..*","",clean_taxonomy, fixed=FALSE)) %>%#removes whats after the ;
  pivot_wider(names_from = clean_taxonomy, values_from = density_n100m2, values_fill = 0, values_fn = sum)%>%
  select("SampID",sort(colnames(.))) #nice to have the cols alphabetical

head(wideData)

```

#output dataset
```{r}
#write.csv(wideData, file=file.path(dataPath,(paste0("widedataOslo_", Sys.Date(),".csv"))))# Whole dataset "OSLO"
write.csv(wideData, file=file.path(dataPath,(paste0("widedata_", Sys.Date(),".csv"))))# 1 per R dataset
```

# ALIGN ENV dataset to final selection of samples
```{r}
# import env data main...
envData<-read.csv(file.path(dataPath,"samples_env_plus.csv"))
envData<- envData %>% select(!c("sw_spd_max","sw_spd_mean")) #remove sandwave area data - not useful in biotope analysis

#import sedMeans (video analysis sed percentages)
sedVid_long<-read.csv(file.path(dataPath,"sedimMeans.csv")) %>% as.data.frame
sedVid<-sedVid_long %>% pivot_wider(id_cols=SampID,
                                    names_from = vSubstrate,
                                    values_from=mean_percent,
                                    values_fill=NA)

envData<-left_join(envData,sedVid, by=c("SampID"))

#import trawlmarks
trawlm <- read.csv(file.path(dataPath,"removed_observations.csv"), sep ="|") #i.e. non-species
trawlm <- trawlm %>% separate(col=clean_taxonomy, into = c("observation_main", "observation_modifier"), sep =";") %>%
  filter(observation_main == "Trawl mark")

trawlwide <- trawlm %>% pivot_wider(names_from = observation_main,
                                    values_from = density_n_100m2,
                                    values_fill = 0,
                                    values_fn = sum) %>%
  select(c("SampID","Trawl mark"))

envData<-left_join(envData,trawlwide, by=c("SampID"))

envData_f<-envData%>% filter(SampID%in%wideData$SampID) 
length(unique(envData_f$SampID)) # number of samples in env dataset
table(duplicated(envData_f$SampID))
envData_f$SampID[duplicated(envData_f$SampID)]

env_fin_spat <- envData_f %>%
  select(x_coord,y_coord) %>%
  SpatialPoints

par(mar = c(0, 0, 0, 0) + 0.1)
plot(gbk, border="green")
plot(env_fin_spat, axes = FALSE, cex = 0.6, add = TRUE) 
box() 
```

# View vars
```{r}
envData_f<-envData_f %>% select(!c("X.1",
                                   "Join_Count",
                                   "TARGET_FID",
                                   "SampID_X",
                                   "SampID_Y", 
                                   "Shrtr133m",
                                   "SampID2_X",
                                   "SampID2_Y",
                                   "m_min", 
                                   "m_max", 
                                   "OBJECTID"))
colnames(envData_f)
```



```{r}
#write.csv(envData_f, file=file.path(dataPath,(paste0("envDataOslo_", Sys.Date(),".csv"))))# Whole dataset "OSLO"
write.csv(envData_f, file=file.path(dataPath,(paste0("envData_", Sys.Date(),".csv"))))# 1 per R dataset
```

# clean up- don't need to have all loaded for next steps
```{r}
rm(list= ls()[!(ls() %in% c('dataPath','outPath', 'sppdens','refer', 'sample_info','taxonary',
                            'utmize','classreport','spquery', 'getsamplesingrp'))]) 
```
